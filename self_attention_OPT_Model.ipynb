{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBqV1lP6g9qbD6YzyF3/Y4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a095b2f8f5243b7b2c3fe31eae716f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78f0494084804c19b46b6531a3340370",
              "IPY_MODEL_dd345f0836424451ad7ecb036a4a4eec",
              "IPY_MODEL_2a8e47632bb04a338f995edddaf3ef8d"
            ],
            "layout": "IPY_MODEL_94f9c132a39347f4a344190263c60e92"
          }
        },
        "78f0494084804c19b46b6531a3340370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abbb1d0b7bf1482681fde6bc10820ac5",
            "placeholder": "​",
            "style": "IPY_MODEL_22728c26daa74369ab03ac0fcbc390fb",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "dd345f0836424451ad7ecb036a4a4eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f68176ed2ea4c42b293471473c47738",
            "max": 2631639353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e68394f8740b405e82b5cbc74ef47bce",
            "value": 2631639353
          }
        },
        "2a8e47632bb04a338f995edddaf3ef8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de63177ebe542ec8512df7eb2454ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_dc7a4c1eee5b42d2b743180328fb0b4d",
            "value": " 2.63G/2.63G [00:15&lt;00:00, 217MB/s]"
          }
        },
        "94f9c132a39347f4a344190263c60e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbb1d0b7bf1482681fde6bc10820ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22728c26daa74369ab03ac0fcbc390fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f68176ed2ea4c42b293471473c47738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e68394f8740b405e82b5cbc74ef47bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6de63177ebe542ec8512df7eb2454ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc7a4c1eee5b42d2b743180328fb0b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f9a0b6ef3814da5aa6df8c9e7849434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_051f5a1532cc416f9cbddd1a37fe032c",
              "IPY_MODEL_e74f6d9be80e40d0b478b69d280ddf69",
              "IPY_MODEL_bfd5fd009b5d4390adc13a214b7fe2bf"
            ],
            "layout": "IPY_MODEL_f0706728022849d0beb86a9cf6e715f1"
          }
        },
        "051f5a1532cc416f9cbddd1a37fe032c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b544ddfe2e5542d68c30bce0a7cb8f40",
            "placeholder": "​",
            "style": "IPY_MODEL_ff3f0ec5b6cb4de8856ba154a6772ba2",
            "value": "generation_config.json: 100%"
          }
        },
        "e74f6d9be80e40d0b478b69d280ddf69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a79109127b284d75b4433fce1cc7dde8",
            "max": 137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbf06f296b9a49ad839733ddf5261acf",
            "value": 137
          }
        },
        "bfd5fd009b5d4390adc13a214b7fe2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_310e770c34f842e2823fa3c004c7be3a",
            "placeholder": "​",
            "style": "IPY_MODEL_ce6a7ed0375345bbbcec944e5ea126d1",
            "value": " 137/137 [00:00&lt;00:00, 3.88kB/s]"
          }
        },
        "f0706728022849d0beb86a9cf6e715f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b544ddfe2e5542d68c30bce0a7cb8f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff3f0ec5b6cb4de8856ba154a6772ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a79109127b284d75b4433fce1cc7dde8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbf06f296b9a49ad839733ddf5261acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "310e770c34f842e2823fa3c004c7be3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce6a7ed0375345bbbcec944e5ea126d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somnathsingh31/inside_LLM_Architecture/blob/main/self_attention_OPT_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "3jGhMtYnF43F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qyxaLIqGECG4"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are using a pretrained model, it’s important to use the associated pretrained tokenizer. This ensures the text is split the same way as the pretraining corpus, and uses the same corresponding tokens-to-index (usually referred to as the vocab) during pretraining."
      ],
      "metadata": {
        "id": "Q-cXjVRdIYRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\", load_in_8bit=True)"
      ],
      "metadata": {
        "id": "OIKwLH_CFmWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load Model:- Open Pretrained Transformers (OPT), a suite of decoder-only pre-trained transformers\n",
        "OPT = AutoModelForCausalLM.from_pretrained(\"facebook/opt-1.3b\", load_in_8bit=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "3a095b2f8f5243b7b2c3fe31eae716f2",
            "78f0494084804c19b46b6531a3340370",
            "dd345f0836424451ad7ecb036a4a4eec",
            "2a8e47632bb04a338f995edddaf3ef8d",
            "94f9c132a39347f4a344190263c60e92",
            "abbb1d0b7bf1482681fde6bc10820ac5",
            "22728c26daa74369ab03ac0fcbc390fb",
            "9f68176ed2ea4c42b293471473c47738",
            "e68394f8740b405e82b5cbc74ef47bce",
            "6de63177ebe542ec8512df7eb2454ba9",
            "dc7a4c1eee5b42d2b743180328fb0b4d",
            "4f9a0b6ef3814da5aa6df8c9e7849434",
            "051f5a1532cc416f9cbddd1a37fe032c",
            "e74f6d9be80e40d0b478b69d280ddf69",
            "bfd5fd009b5d4390adc13a214b7fe2bf",
            "f0706728022849d0beb86a9cf6e715f1",
            "b544ddfe2e5542d68c30bce0a7cb8f40",
            "ff3f0ec5b6cb4de8856ba154a6772ba2",
            "a79109127b284d75b4433fce1cc7dde8",
            "cbf06f296b9a49ad839733ddf5261acf",
            "310e770c34f842e2823fa3c004c7be3a",
            "ce6a7ed0375345bbbcec944e5ea126d1"
          ]
        },
        "id": "YgnkVX2RET9O",
        "outputId": "25f23441-cc61-4863-e661-fea7dcd586a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a095b2f8f5243b7b2c3fe31eae716f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f9a0b6ef3814da5aa6df8c9e7849434"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"The quick brown fox jumps over the lazy dog\""
      ],
      "metadata": {
        "id": "RTjtKKDjF0kw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#return_tensors parameter to either pt for PyTorch, or tf for TensorFlow\n",
        "inp_tokenized = tokenizer(inp, return_tensors='pt')"
      ],
      "metadata": {
        "id": "WDO4tN_6HLx7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inp_tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLLEpqJrIQ_S",
        "outputId": "0fb4d219-7386-4c80-fa63-80cfc8fd3861"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    2,   133,  2119,  6219, 23602, 13855,    81,     5, 22414,  2335]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inp_tokenized['input_ids'].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOz5QUWaIflS",
        "outputId": "a3c55f50-bf6d-4f87-c2d5-c05a8f55bfae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(OPT.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "occCuFvIIz9L",
        "outputId": "9100f975-d0fb-482a-a6e2-c0f474a832fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPTModel(\n",
            "  (decoder): OPTDecoder(\n",
            "    (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n",
            "    (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n",
            "    (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x OPTDecoderLayer(\n",
            "        (self_attn): OPTAttention(\n",
            "          (k_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_fn): ReLU()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear8bitLt(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear8bitLt(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPTDecoder\n",
        "\n",
        "The decoder component of the transformer model. It consists of:\n",
        "\n",
        "- **embed_tokens**: An embedding layer that maps input tokens to vectors.\n",
        "  - Vocabulary size: 50,272 tokens.\n",
        "  - Embedding dimension: 2,048.\n",
        "  - Padding token index: 1.\n",
        "\n",
        "- **embed_positions**: A learned positional embedding layer.\n",
        "  - Maximum sequence length: 2,050.\n",
        "  - Embedding dimension: 2,048.\n",
        "\n",
        "- **final_layer_norm**: A layer normalization layer.\n",
        "  - Normalizes the output of the decoder.\n",
        "  - Epsilon (smoothing factor): 1e-5.\n",
        "\n",
        "- **layers**: A list of 24 identical decoder layers (OPTDecoderLayer).\n",
        "\n",
        "### OPTDecoderLayer\n",
        "\n",
        "A single decoder layer. It consists of:\n",
        "\n",
        "- **self_attn**: A self-attention mechanism (OPTAttention).\n",
        "  - Query, key, and value projections (Linear8bitLt).\n",
        "  - Output projection (Linear8bitLt).\n",
        "\n",
        "- **activation_fn**: A ReLU activation function.\n",
        "\n",
        "- **self_attn_layer_norm**: A layer normalization layer.\n",
        "  - Normalizes the output of self-attention.\n",
        "  - Epsilon: 1e-5.\n",
        "\n",
        "- **fc1 and fc2**: Two linear layers (Linear8bitLt) with:\n",
        "  - Input dimension: 2,048.\n",
        "  - Output dimension: 8,192 (fc1) and 2,048 (fc2).\n",
        "\n",
        "- **final_layer_norm**: A layer normalization layer.\n",
        "  - Normalizes the output of the decoder layer.\n",
        "  - Epsilon: 1e-5.\n",
        "\n",
        "### Linear8bitLt\n",
        "\n",
        "A linear layer with 8-bit quantization. This suggests the model is optimized for efficient inference.\n"
      ],
      "metadata": {
        "id": "bHmQlLZsNACC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7AtdDIK2SLDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above model, the trainable parameters are the weights and biases of the following layers:\n",
        "\n",
        "### Embedding layers:\n",
        "- **embed_tokens**: weights (50,272 x 2,048)\n",
        "- **embed_positions**: weights (2,050 x 2,048)\n",
        "\n",
        "### Linear layers within OPTDecoderLayer:\n",
        "- **k_proj**: weights (2,048 x 2,048) and bias (2,048)\n",
        "- **v_proj**: weights (2,048 x 2,048) and bias (2,048)\n",
        "- **q_proj**: weights (2,048 x 2,048) and bias (2,048)\n",
        "- **out_proj**: weights (2,048 x 2,048) and bias (2,048)\n",
        "- **fc1**: weights (2,048 x 8,192) and bias (8,192)\n",
        "- **fc2**: weights (8,192 x 2,048) and bias (2,048)\n",
        "\n",
        "### LayerNorm layers:\n",
        "- **final_layer_norm** (in OPTDecoder): weights (2,048) and bias (2,048)\n",
        "- **self_attn_layer_norm** (in OPTDecoderLayer): weights (2,048) and bias (2,048)\n",
        "- **final_layer_norm** (in OPTDecoderLayer): weights (2,048) and bias (2,048)\n",
        "\n",
        "> **Note**: The ReLU activation function does not have any trainable parameters.\n",
        "\n",
        "In total, there are 24 OPTDecoderLayer instances, each with its own set of trainable parameters. This results in a large number of trainable parameters, specifically:\n",
        "\n",
        "- **Embedding layers**: 50,272 x 2,048 + 2,050 x 2,048\n",
        "- **Linear layers**: 24 x (4 x (2,048 x 2,048 + 2,048) + 2 x (2,048 x 8,192 + 8,192))\n",
        "- **LayerNorm layers**: 24 x 2 x (2,048 + 2,048) + 1 x (2,048 + 2,048)\n",
        "\n",
        "This is approximately **1.3 billion trainable parameters**.\n"
      ],
      "metadata": {
        "id": "Xd6YboOhSMYa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IUNJN9WoSSpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The embedding layer is accessed via decoder object's .embed_tokens method. The embedding layer will convert a list of token IDs of size [1,10] to [1,10,2048]"
      ],
      "metadata": {
        "id": "YCMqN5AlNv50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_input = OPT.model.decoder.embed_tokens(inp_tokenized['input_ids'])\n",
        "print(embeded_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUiNEB6FJLWd",
        "outputId": "0020dace-90ee-48ae-eff7-87f150f0a853"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0407,  0.0519,  0.0574,  ..., -0.0263, -0.0355, -0.0260],\n",
            "         [-0.0371,  0.0220, -0.0096,  ...,  0.0265, -0.0166, -0.0030],\n",
            "         [-0.0455, -0.0236, -0.0121,  ...,  0.0043, -0.0166,  0.0193],\n",
            "         ...,\n",
            "         [ 0.0007,  0.0267,  0.0257,  ...,  0.0622,  0.0421,  0.0279],\n",
            "         [-0.0126,  0.0347, -0.0352,  ..., -0.0393, -0.0396, -0.0102],\n",
            "         [-0.0115,  0.0319,  0.0274,  ..., -0.0472, -0.0059,  0.0341]]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeded_input.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuYeDNuZMmM1",
        "outputId": "0879f3b6-b5f9-4c1e-ddf4-33635a6683ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# positional embedding\n",
        "embed_pos_input = OPT.model.decoder.embed_positions(inp_tokenized['attention_mask'])\n",
        "\n",
        "print(\"Layer: \\t\", OPT.model.decoder.embed_positions)\n",
        "print(\"Size: \\t\", embed_pos_input.size())\n",
        "print(\"Output: \\t\", embed_pos_input)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw7CfNNHMtXV",
        "outputId": "794a6d41-3def-4f03-bfbe-4f2055ce0b0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: \t OPTLearnedPositionalEmbedding(2050, 2048)\n",
            "Size: \t torch.Size([1, 10, 2048])\n",
            "Output: \t tensor([[[-8.1406e-03, -2.6221e-01,  6.0768e-03,  ...,  1.7273e-02,\n",
            "          -5.0621e-03, -1.6220e-02],\n",
            "         [-8.0585e-05,  2.5000e-01, -1.6632e-02,  ..., -1.5419e-02,\n",
            "          -1.7838e-02,  2.4948e-02],\n",
            "         [-9.9411e-03, -1.4978e-01,  1.7557e-03,  ...,  3.7117e-03,\n",
            "          -1.6434e-02, -9.9087e-04],\n",
            "         ...,\n",
            "         [ 3.6979e-04, -7.7454e-02,  1.2955e-02,  ...,  3.9330e-03,\n",
            "          -1.1642e-02,  7.8506e-03],\n",
            "         [-2.6779e-03, -2.2446e-02, -1.6754e-02,  ..., -1.3142e-03,\n",
            "          -7.8583e-03,  2.0096e-02],\n",
            "         [-8.6288e-03,  1.4233e-01, -1.9012e-02,  ..., -1.8463e-02,\n",
            "          -9.8572e-03,  8.7662e-03]]], device='cuda:0', dtype=torch.float16,\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_position_inut = embeded_input + embed_pos_input\n"
      ],
      "metadata": {
        "id": "03NXr1i-U4EM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#There are 24 such decoder layers in OPT model. In each layer we can see, self attention, activation function, self_attn_layer_norm, two fullu connected layers.\n",
        "OPT.model.decoder.layers[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIK4HrKxWA0M",
        "outputId": "272d93bb-0eb0-433c-daff-f2673183ea2d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OPTDecoderLayer(\n",
              "  (self_attn): OPTAttention(\n",
              "    (k_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
              "    (v_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
              "    (q_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
              "    (out_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
              "  )\n",
              "  (activation_fn): ReLU()\n",
              "  (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc1): Linear8bitLt(in_features=2048, out_features=8192, bias=True)\n",
              "  (fc2): Linear8bitLt(in_features=8192, out_features=2048, bias=True)\n",
              "  (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Three outputs:**\n",
        "\n",
        "The self_attn module in the OPT model returns three tensors:\n",
        "\n",
        "**attention_output:** The weighted sum of the value projections, shaped as (batch_size, sequence_length, embed_dim).\n",
        "\n",
        "**attention_weights:** The attention weights, shaped as (batch_size, num_heads, sequence_length, sequence_length).\n",
        "\n",
        "**intermediate_result:** An intermediate result used for reversible attention (optional, but present in OPT)."
      ],
      "metadata": {
        "id": "IRE5YAnGYbp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_output,_ , _ = OPT.model.decoder.layers[0].self_attn(embed_position_inut)"
      ],
      "metadata": {
        "id": "4atIObUIVoNp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Layer: \\t\", OPT.model.decoder.layers[0].self_attn)\n",
        "print(\"Size: \\t\", attention_output.size(), \"\\n\")\n",
        "print(\"Output: \\t\", attention_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUki_nCWXFND",
        "outputId": "8d1240c2-62e4-4ce7-bdd1-2edc72da2c5f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: \t OPTAttention(\n",
            "  (k_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
            "  (v_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
            "  (q_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
            "  (out_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=True)\n",
            ")\n",
            "Size: \t torch.Size([1, 10, 2048]) \n",
            "\n",
            "Output: \t tensor([[[-0.0119, -0.0110,  0.0056,  ...,  0.0094,  0.0013,  0.0093],\n",
            "         [-0.0119, -0.0110,  0.0056,  ...,  0.0095,  0.0013,  0.0093],\n",
            "         [-0.0119, -0.0110,  0.0056,  ...,  0.0095,  0.0013,  0.0093],\n",
            "         ...,\n",
            "         [-0.0119, -0.0110,  0.0056,  ...,  0.0095,  0.0013,  0.0093],\n",
            "         [-0.0119, -0.0110,  0.0056,  ...,  0.0095,  0.0013,  0.0093],\n",
            "         [-0.0119, -0.0110,  0.0056,  ...,  0.0095,  0.0013,  0.0093]]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<MatMul8bitLtBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Activation function output\n",
        "activation_fn_output = OPT.model.decoder.layers[0].activation_fn(attention_output)"
      ],
      "metadata": {
        "id": "A8HF4J-kaher"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Layer: \\t\", OPT.model.decoder.layers[0].activation_fn)\n",
        "print(\"Size: \\t\", activation_fn_output.size(), \"\\n\")\n",
        "print(\"Output: \\t\", activation_fn_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3FytuUZbCLh",
        "outputId": "63562d8f-1a35-47e4-a51e-f9d29caf8e45"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: \t ReLU()\n",
            "Size: \t torch.Size([1, 10, 2048]) \n",
            "\n",
            "Output: \t tensor([[[0.0000, 0.0000, 0.0056,  ..., 0.0094, 0.0013, 0.0093],\n",
            "         [0.0000, 0.0000, 0.0056,  ..., 0.0095, 0.0013, 0.0093],\n",
            "         [0.0000, 0.0000, 0.0056,  ..., 0.0095, 0.0013, 0.0093],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0056,  ..., 0.0095, 0.0013, 0.0093],\n",
            "         [0.0000, 0.0000, 0.0056,  ..., 0.0095, 0.0013, 0.0093],\n",
            "         [0.0000, 0.0000, 0.0056,  ..., 0.0095, 0.0013, 0.0093]]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#self_attn_layer_norm output\n",
        "self_attn_layer_norm_output = OPT.model.decoder.layers[0].self_attn_layer_norm(activation_fn_output)"
      ],
      "metadata": {
        "id": "cyysdmvsbo9v"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Layer: \\t\", OPT.model.decoder.layers[0].self_attn_layer_norm)\n",
        "print(\"Size: \\t\", self_attn_layer_norm_output.size(), \"\\n\")\n",
        "print(\"Output: \\t\", self_attn_layer_norm_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz8QDB5NcIQR",
        "outputId": "5b982755-656f-47c6-fba2-c8a2587a22ac"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: \t LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "Size: \t torch.Size([1, 10, 2048]) \n",
            "\n",
            "Output: \t tensor([[[-0.0297, -0.0003, -0.0809,  ..., -0.0103, -0.0086, -0.0093],\n",
            "         [-0.0298, -0.0004, -0.0807,  ..., -0.0100, -0.0086, -0.0092],\n",
            "         [-0.0298, -0.0004, -0.0803,  ..., -0.0098, -0.0090, -0.0091],\n",
            "         ...,\n",
            "         [-0.0298, -0.0003, -0.0810,  ..., -0.0098, -0.0091, -0.0091],\n",
            "         [-0.0297, -0.0003, -0.0809,  ..., -0.0099, -0.0089, -0.0091],\n",
            "         [-0.0298, -0.0004, -0.0802,  ..., -0.0100, -0.0089, -0.0092]]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fc1 output\n",
        "fc1_output = OPT.model.decoder.layers[0].fc1(self_attn_layer_norm_output)\n",
        "print(\"Layer: \\t\", OPT.model.decoder.layers[0].fc1)\n",
        "print(\"Size: \\t\", fc1_output.size(), \"\\n\")\n",
        "print(\"Output: \\t\", fc1_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD4qHuRBcOH5",
        "outputId": "71b80c37-fe32-4d20-9f85-e77d5bff0a48"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: \t Linear8bitLt(in_features=2048, out_features=8192, bias=True)\n",
            "Size: \t torch.Size([1, 10, 8192]) \n",
            "\n",
            "Output: \t tensor([[[0.1697, 0.4006, 0.1063,  ..., 0.2170, 0.1257, 0.0748],\n",
            "         [0.1711, 0.4009, 0.1044,  ..., 0.2166, 0.1252, 0.0759],\n",
            "         [0.1687, 0.4016, 0.1060,  ..., 0.2180, 0.1233, 0.0735],\n",
            "         ...,\n",
            "         [0.1694, 0.4028, 0.1036,  ..., 0.2180, 0.1251, 0.0746],\n",
            "         [0.1696, 0.4023, 0.1064,  ..., 0.2188, 0.1250, 0.0756],\n",
            "         [0.1685, 0.4023, 0.1066,  ..., 0.2168, 0.1241, 0.0732]]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<MatMul8bitLtBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fc2 output\n",
        "fc2_output = OPT.model.decoder.layers[0].fc2(fc1_output)\n",
        "print(\"Layer: \\t\", OPT.model.decoder.layers[0].fc2)\n",
        "print(\"Size: \\t\", fc2_output.size(), \"\\n\")\n",
        "print(\"Output: \\t\", fc2_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxxtmemzcxJt",
        "outputId": "3f733e2b-6e1a-4a02-e021-b842d8b946e8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: \t Linear8bitLt(in_features=8192, out_features=2048, bias=True)\n",
            "Size: \t torch.Size([1, 10, 2048]) \n",
            "\n",
            "Output: \t tensor([[[ 2.3164,  1.1621,  3.1191,  ..., -0.6309, -0.8525,  0.4644],\n",
            "         [ 2.3164,  1.1729,  3.1309,  ..., -0.6323, -0.8521,  0.4561],\n",
            "         [ 2.3027,  1.1777,  3.1289,  ..., -0.6587, -0.8359,  0.4490],\n",
            "         ...,\n",
            "         [ 2.3047,  1.1504,  3.1152,  ..., -0.6270, -0.8496,  0.4744],\n",
            "         [ 2.3027,  1.1699,  3.1348,  ..., -0.6494, -0.8403,  0.4480],\n",
            "         [ 2.2949,  1.1787,  3.1348,  ..., -0.6533, -0.8354,  0.4607]]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<MatMul8bitLtBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final_layer_norm output\n",
        "final_layer_norm_output = OPT.model.decoder.layers[0].final_layer_norm(fc2_output)\n",
        "print(\"Layer: \\t\", OPT.model.decoder.layers[0].final_layer_norm)\n",
        "print(\"Size: \\t\", final_layer_norm_output.size(), \"\\n\")\n",
        "print(\"Output: \\t\", final_layer_norm_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7oAUho8dCsq",
        "outputId": "7f2fdad1-e228-4608-df20-f445a173dfb3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: \t LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "Size: \t torch.Size([1, 10, 2048]) \n",
            "\n",
            "Output: \t tensor([[[ 0.9146,  0.3237,  1.5127,  ..., -0.1781, -0.5068,  0.3682],\n",
            "         [ 0.9175,  0.3301,  1.5225,  ..., -0.1794, -0.5078,  0.3650],\n",
            "         [ 0.9111,  0.3323,  1.5205,  ..., -0.1915, -0.5000,  0.3618],\n",
            "         ...,\n",
            "         [ 0.9092,  0.3184,  1.5117,  ..., -0.1763, -0.5054,  0.3728],\n",
            "         [ 0.9102,  0.3281,  1.5225,  ..., -0.1870, -0.5020,  0.3611],\n",
            "         [ 0.9077,  0.3328,  1.5244,  ..., -0.1892, -0.5000,  0.3672]]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The embedded input size is also torch.Size([1, 10, 2048]), which is the same as the final output size mentioned above."
      ],
      "metadata": {
        "id": "V4szDuz3dhZV"
      }
    }
  ]
}